### Target Backdoor Attacks on Deep Learning System using Data Poisoning

## Introduction
- Attacker: Create a backdoor into a learning-based authentication system
- Backdoor Poisoning Attack -target attack
- Weak and realistic model:
    * attacker has no knowledge of the victim model or its training data
    * attacker can inject only a small number of poisoning samples into training data
- 2 poisoning strategies:
    1> attacker injects few poisoning sample
    2> attacker create a wide range of backdoor instances
    
## Thread Model
- Black-box poisoning
- Unawareness of training data
- Tageted attacks: \\ any back door instances will be classified as a target lable; the overall performance of learning system will not be affected.
